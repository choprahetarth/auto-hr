{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPJvoLs4N4c6YKxzCFB+Qg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choprahetarth/auto-hr/blob/main/LLaMA_Index_PoC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jerryjliu/llama_index.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLDVccyhnkCp",
        "outputId": "954f3f0f-b308-49f1-f238-ea1090b3aff2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama_index'...\n",
            "remote: Enumerating objects: 21219, done.\u001b[K\n",
            "remote: Counting objects: 100% (5301/5301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1317/1317), done.\u001b[K\n",
            "remote: Total 21219 (delta 4346), reused 4382 (delta 3965), pack-reused 15918\u001b[K\n",
            "Receiving objects: 100% (21219/21219), 54.52 MiB | 24.33 MiB/s, done.\n",
            "Resolving deltas: 100% (14616/14616), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index\n",
        "!pip install unstructured\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIhnjw7P6GfL",
        "outputId": "4464ef3f-a36f-4e99-a43d-09d58f5260b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.7.4-py3-none-any.whl (580 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.0/580.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from llama_index)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama_index)\n",
            "  Downloading dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
            "Collecting langchain>=0.0.218 (from llama_index)\n",
            "  Downloading langchain-0.0.228-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.2)\n",
            "Collecting openai>=0.26.4 (from llama_index)\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.26.16)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Collecting typing-inspect==0.8.0 (from llama_index)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting typing-extensions==4.5.0 (from llama_index)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.11.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.6)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect==0.8.0->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (6.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (4.0.2)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain>=0.0.218->llama_index)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain>=0.0.218->llama_index)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (1.10.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (2.27.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json->llama_index)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json->llama_index)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama_index) (4.65.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama_index) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama_index) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama_index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama_index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama_index) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama_index) (3.4)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, typing-inspect, tiktoken, marshmallow-enum, openapi-schema-pydantic, openai, langchainplus-sdk, dataclasses-json, langchain, llama_index\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "Successfully installed dataclasses-json-0.5.9 langchain-0.0.228 langchainplus-sdk-0.0.20 llama_index-0.7.4 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 tiktoken-0.4.0 typing-extensions-4.5.0 typing-inspect-0.8.0\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argilla (from unstructured)\n",
            "  Downloading argilla-1.12.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.2)\n",
            "Collecting msg-parser (from unstructured)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Collecting pdf2image (from unstructured)\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Collecting pypandoc (from unstructured)\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured)\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.10)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Collecting httpx<0.24,>=0.15 (from argilla->unstructured)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (23.1)\n",
            "Requirement already satisfied: pydantic>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.10.9)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Collecting backoff (from argilla->unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting monotonic (from argilla->unstructured)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting rich<=13.0.1 (from argilla->unstructured)\n",
            "  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.8.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (2.0.12)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured)\n",
            "  Downloading cryptography-41.0.1-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting XlsxWriter>=0.5.7 (from python-pptx->unstructured)\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->argilla->unstructured) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<=13.0.1->argilla->unstructured)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (1.1.1)\n",
            "Building wheels for collected packages: python-docx, python-pptx, olefile\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=b54b18b706c7663537bba97d379dc0eab91f9e6ac645fbb260c5f0fa15e31705\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=a2896e91ea2faf8fd89c2bb3a2f43d20189d9800e8895d23d5c851014c0b671c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=4745ed4acc509ea6c92e57c95e2114ab20ca661d5205d9454f0c3e0ee4e17942\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built python-docx python-pptx olefile\n",
            "Installing collected packages: rfc3986, monotonic, filetype, commonmark, XlsxWriter, rich, python-magic, python-docx, pypandoc, pdf2image, olefile, h11, deprecated, backoff, python-pptx, msg-parser, httpcore, cryptography, pdfminer.six, httpx, argilla, unstructured\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.4.2\n",
            "    Uninstalling rich-13.4.2:\n",
            "      Successfully uninstalled rich-13.4.2\n",
            "Successfully installed XlsxWriter-3.1.2 argilla-1.12.0 backoff-2.2.1 commonmark-0.9.1 cryptography-41.0.1 deprecated-1.2.14 filetype-1.2.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 monotonic-1.6 msg-parser-1.2.0 olefile-0.46 pdf2image-1.16.3 pdfminer.six-20221105 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 rfc3986-1.5.0 rich-13.0.1 unstructured-0.8.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "import openai\n",
        "elements = partition_pdf(\"/content/Hetarth_Chopra_Resume_preMS_ML.pdf\")"
      ],
      "metadata": {
        "id": "Va-GtNCu9KdK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "0rxPo0e7CEcc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_string = \"\"\n",
        "for x in elements:\n",
        "  output_string+=str(x)"
      ],
      "metadata": {
        "id": "cENj_wec-zjj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = open(\"/content/llama_index/examples/paul_graham_essay/data/sample.txt\", \"wt\")\n",
        "n = text_file.write(output_string)\n",
        "text_file.close()"
      ],
      "metadata": {
        "id": "FsiG-MjK_LbU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader('/content/llama_index/examples/paul_graham_essay/data').load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "6HkhNg4bCMfB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"Please tell me about all ML Projects Hetarth has worked on?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dDTobHk_5eu",
        "outputId": "5a0a3216-e54f-4d3f-a10a-5fb03d21377c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hetarth has worked on a variety of Machine Learning projects, including: \n",
            "\n",
            "1. Image Enhancer tool for E-Commerce, which used DeblurGAN to sharpen product images and increase PSNR by 34%. \n",
            "\n",
            "2. Romanization for Product Search Enhancement, which developed a Transliteration Python library by fine-tuning IndicNLP's from 11 Indian Languages. \n",
            "\n",
            "3. Product Price Range Estimation for Fraud Detection, which developed a product-name-based price estimation model with the help of MiniLM and KNN search in ElasticSearch. \n",
            "\n",
            "4. Automatic Product-Colour Variant Matching Algorithm, which used Faster RCNN to remove background from product images, and applied K-Means Clustering to get the most dominant colors. \n",
            "\n",
            "5. Automatic Image Orientation Correction, which achieved an 87% accuracy in detecting improperly oriented images by fine-tuning a Vision Transformer model in PyTorch. \n",
            "\n",
            "6. Fabricated a Machine Learning tool to classify requirements in the Metro RFP (request for proposal), for each sub-system with NLP using TFIDF, Word2Vec, and XgBoost. \n",
            "\n",
            "7. Collaborated with the civil engineering department, in an inter-university research effort to train a model for predicting concrete's compressive strength. \n",
            "\n",
            "8. Developed a Python Script for human distance estimation using Zed Depth Camera. \n",
            "\n",
            "9. Developed a unique Robot Calibration Protocol with ROS and wheel encoders, increasing the robot odometry accuracy by 11.5%. \n",
            "\n",
            "10. Created a custom dataset using a low-cost Spectrophotometry sensor for apples and their fruit grade. Further predictive modeling was done to classify apples into their food grades with a 72% accuracy. \n",
            "\n",
            "11. Converted gearbox vibration time-series data into spectrograms of different classes of damaged and healthy gearboxes. Used Transfer Learning with the help of pre-trained CNN Architectures such as VGG-16, Resnet50, EfficientNet, etc. to classify the gearbox in different damage categories based on the vibration with 99.14% accuracy. \n",
            "\n",
            "12. Developed a methodology to identify gearbox vibrations as faulty or not, after extracting time series features using Random Trees. With the help of ANN, the time features were used to train a classification model providing an accuracy of 88.9% in classifying the gearboxes. \n",
            "\n",
            "13. Developed an API with the help of Flask and pre-trained Detectron - 2, in order to extract images using instance segmentation. Achieved an 0.83 IoU Score by replicating the results after training a custom U-Net Based model on the MS- COCO Dataset using Tensorflow-Keras. \n",
            "\n",
            "14. Developed a Transfer-Learning based solution, for counting push-up reps during COVID-19 lockdown, by implementing a pre-trained MobileNet-V2. The overall prediction accuracy peaked at 90.76%. \n",
            "\n",
            "15. Developed an NLP Pipeline to extract a research paper's PDF and with 90.1% accuracy, find the contributing statements. The Flask API also clubs them together to form a Research Paper's Abstract.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RxZ52-MYBwkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dqJX1vJuBwh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}